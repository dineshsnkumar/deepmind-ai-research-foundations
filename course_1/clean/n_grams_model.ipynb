{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8O1TpDqtQqh87BS/612Qt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in Building a N grams model\n",
        "\n",
        "- Tokenize the dataset and get n grams\n",
        "- Count the n grams\n",
        "- Compute N-gram probability\n",
        "- Generate token based on the n-gram model\n",
        "\n"
      ],
      "metadata": {
        "id": "lcfY5_5NdCK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, textwrap\n",
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "9ysGJjPYeKuK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize the dataset and get n-grams\n"
      ],
      "metadata": {
        "id": "kwkkJACvern7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys. The wife did not leave her own room, the husband had not been at home for three days. The children ran wild all over the house; the English governess quarreled with the housekeeper, and wrote to a friend asking her to look out for a new situation for her; the man-cook had walked off the day before just at dinner time; the kitchen-maid, and the coachman had given warning\"\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7llrfnRve2E4",
        "outputId": "450ac7fc-2079-4b23-dd71-917f4ea9d57c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Every person in the house felt that there was no sense in their living together, and that the stray people brought together by chance in any inn had more in common with one another than they, the members of the family and household of the Oblonskys. The wife did not leave her own room, the husband had not been at home for three days. The children ran wild all over the house; the English governess quarreled with the housekeeper, and wrote to a friend asking her to look out for a new situation for her; the man-cook had walked off the day before just at dinner time; the kitchen-maid, and the coachman had given warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(text:str, n:int) -> list[tuple[str]]:\n",
        "  n_grams = []\n",
        "  # Using basic space tokenizer\n",
        "  text_tokens = text.lower().split(\" \")\n",
        "  length_of_tokens = len(text_tokens)\n",
        "\n",
        "  for i in range(length_of_tokens-n+1):\n",
        "    token = tuple(text_tokens[i:i+n])\n",
        "    n_grams.append(token)\n",
        "\n",
        "  return n_grams\n",
        "\n",
        "generate_ngrams(dataset, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b41qRe0vfKT4",
        "outputId": "914499a4-46bb-4ec4-c74b-0ce1a3ec5fa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happy', 'families', 'are'),\n",
              " ('families', 'are', 'all'),\n",
              " ('are', 'all', 'alike;'),\n",
              " ('all', 'alike;', 'every'),\n",
              " ('alike;', 'every', 'unhappy'),\n",
              " ('every', 'unhappy', 'family'),\n",
              " ('unhappy', 'family', 'is'),\n",
              " ('family', 'is', 'unhappy'),\n",
              " ('is', 'unhappy', 'in'),\n",
              " ('unhappy', 'in', 'its'),\n",
              " ('in', 'its', 'own'),\n",
              " ('its', 'own', 'way.'),\n",
              " ('own', 'way.', 'everything'),\n",
              " ('way.', 'everything', 'was'),\n",
              " ('everything', 'was', 'in'),\n",
              " ('was', 'in', 'confusion'),\n",
              " ('in', 'confusion', 'in'),\n",
              " ('confusion', 'in', 'the'),\n",
              " ('in', 'the', 'oblonskys’'),\n",
              " ('the', 'oblonskys’', 'house.'),\n",
              " ('oblonskys’', 'house.', 'the'),\n",
              " ('house.', 'the', 'wife'),\n",
              " ('the', 'wife', 'had'),\n",
              " ('wife', 'had', 'discovered'),\n",
              " ('had', 'discovered', 'that'),\n",
              " ('discovered', 'that', 'the'),\n",
              " ('that', 'the', 'husband'),\n",
              " ('the', 'husband', 'was'),\n",
              " ('husband', 'was', 'carrying'),\n",
              " ('was', 'carrying', 'on'),\n",
              " ('carrying', 'on', 'an'),\n",
              " ('on', 'an', 'intrigue'),\n",
              " ('an', 'intrigue', 'with'),\n",
              " ('intrigue', 'with', 'a'),\n",
              " ('with', 'a', 'french'),\n",
              " ('a', 'french', 'girl,'),\n",
              " ('french', 'girl,', 'who'),\n",
              " ('girl,', 'who', 'had'),\n",
              " ('who', 'had', 'been'),\n",
              " ('had', 'been', 'a'),\n",
              " ('been', 'a', 'governess'),\n",
              " ('a', 'governess', 'in'),\n",
              " ('governess', 'in', 'their'),\n",
              " ('in', 'their', 'family,'),\n",
              " ('their', 'family,', 'and'),\n",
              " ('family,', 'and', 'she'),\n",
              " ('and', 'she', 'had'),\n",
              " ('she', 'had', 'announced'),\n",
              " ('had', 'announced', 'to'),\n",
              " ('announced', 'to', 'her'),\n",
              " ('to', 'her', 'husband'),\n",
              " ('her', 'husband', 'that'),\n",
              " ('husband', 'that', 'she'),\n",
              " ('that', 'she', 'could'),\n",
              " ('she', 'could', 'not'),\n",
              " ('could', 'not', 'go'),\n",
              " ('not', 'go', 'on'),\n",
              " ('go', 'on', 'living'),\n",
              " ('on', 'living', 'in'),\n",
              " ('living', 'in', 'the'),\n",
              " ('in', 'the', 'same'),\n",
              " ('the', 'same', 'house'),\n",
              " ('same', 'house', 'with'),\n",
              " ('house', 'with', 'him.'),\n",
              " ('with', 'him.', 'this'),\n",
              " ('him.', 'this', 'position'),\n",
              " ('this', 'position', 'of'),\n",
              " ('position', 'of', 'affairs'),\n",
              " ('of', 'affairs', 'had'),\n",
              " ('affairs', 'had', 'now'),\n",
              " ('had', 'now', 'lasted'),\n",
              " ('now', 'lasted', 'three'),\n",
              " ('lasted', 'three', 'days,'),\n",
              " ('three', 'days,', 'and'),\n",
              " ('days,', 'and', 'not'),\n",
              " ('and', 'not', 'only'),\n",
              " ('not', 'only', 'the'),\n",
              " ('only', 'the', 'husband'),\n",
              " ('the', 'husband', 'and'),\n",
              " ('husband', 'and', 'wife'),\n",
              " ('and', 'wife', 'themselves,'),\n",
              " ('wife', 'themselves,', 'but'),\n",
              " ('themselves,', 'but', 'all'),\n",
              " ('but', 'all', 'the'),\n",
              " ('all', 'the', 'members'),\n",
              " ('the', 'members', 'of'),\n",
              " ('members', 'of', 'their'),\n",
              " ('of', 'their', 'family'),\n",
              " ('their', 'family', 'and'),\n",
              " ('family', 'and', 'household,'),\n",
              " ('and', 'household,', 'were'),\n",
              " ('household,', 'were', 'painfully'),\n",
              " ('were', 'painfully', 'conscious'),\n",
              " ('painfully', 'conscious', 'of'),\n",
              " ('conscious', 'of', 'it.'),\n",
              " ('of', 'it.', 'every'),\n",
              " ('it.', 'every', 'person'),\n",
              " ('every', 'person', 'in'),\n",
              " ('person', 'in', 'the'),\n",
              " ('in', 'the', 'house'),\n",
              " ('the', 'house', 'felt'),\n",
              " ('house', 'felt', 'that'),\n",
              " ('felt', 'that', 'there'),\n",
              " ('that', 'there', 'was'),\n",
              " ('there', 'was', 'no'),\n",
              " ('was', 'no', 'sense'),\n",
              " ('no', 'sense', 'in'),\n",
              " ('sense', 'in', 'their'),\n",
              " ('in', 'their', 'living'),\n",
              " ('their', 'living', 'together,'),\n",
              " ('living', 'together,', 'and'),\n",
              " ('together,', 'and', 'that'),\n",
              " ('and', 'that', 'the'),\n",
              " ('that', 'the', 'stray'),\n",
              " ('the', 'stray', 'people'),\n",
              " ('stray', 'people', 'brought'),\n",
              " ('people', 'brought', 'together'),\n",
              " ('brought', 'together', 'by'),\n",
              " ('together', 'by', 'chance'),\n",
              " ('by', 'chance', 'in'),\n",
              " ('chance', 'in', 'any'),\n",
              " ('in', 'any', 'inn'),\n",
              " ('any', 'inn', 'had'),\n",
              " ('inn', 'had', 'more'),\n",
              " ('had', 'more', 'in'),\n",
              " ('more', 'in', 'common'),\n",
              " ('in', 'common', 'with'),\n",
              " ('common', 'with', 'one'),\n",
              " ('with', 'one', 'another'),\n",
              " ('one', 'another', 'than'),\n",
              " ('another', 'than', 'they,'),\n",
              " ('than', 'they,', 'the'),\n",
              " ('they,', 'the', 'members'),\n",
              " ('the', 'members', 'of'),\n",
              " ('members', 'of', 'the'),\n",
              " ('of', 'the', 'family'),\n",
              " ('the', 'family', 'and'),\n",
              " ('family', 'and', 'household'),\n",
              " ('and', 'household', 'of'),\n",
              " ('household', 'of', 'the'),\n",
              " ('of', 'the', 'oblonskys.'),\n",
              " ('the', 'oblonskys.', 'the'),\n",
              " ('oblonskys.', 'the', 'wife'),\n",
              " ('the', 'wife', 'did'),\n",
              " ('wife', 'did', 'not'),\n",
              " ('did', 'not', 'leave'),\n",
              " ('not', 'leave', 'her'),\n",
              " ('leave', 'her', 'own'),\n",
              " ('her', 'own', 'room,'),\n",
              " ('own', 'room,', 'the'),\n",
              " ('room,', 'the', 'husband'),\n",
              " ('the', 'husband', 'had'),\n",
              " ('husband', 'had', 'not'),\n",
              " ('had', 'not', 'been'),\n",
              " ('not', 'been', 'at'),\n",
              " ('been', 'at', 'home'),\n",
              " ('at', 'home', 'for'),\n",
              " ('home', 'for', 'three'),\n",
              " ('for', 'three', 'days.'),\n",
              " ('three', 'days.', 'the'),\n",
              " ('days.', 'the', 'children'),\n",
              " ('the', 'children', 'ran'),\n",
              " ('children', 'ran', 'wild'),\n",
              " ('ran', 'wild', 'all'),\n",
              " ('wild', 'all', 'over'),\n",
              " ('all', 'over', 'the'),\n",
              " ('over', 'the', 'house;'),\n",
              " ('the', 'house;', 'the'),\n",
              " ('house;', 'the', 'english'),\n",
              " ('the', 'english', 'governess'),\n",
              " ('english', 'governess', 'quarreled'),\n",
              " ('governess', 'quarreled', 'with'),\n",
              " ('quarreled', 'with', 'the'),\n",
              " ('with', 'the', 'housekeeper,'),\n",
              " ('the', 'housekeeper,', 'and'),\n",
              " ('housekeeper,', 'and', 'wrote'),\n",
              " ('and', 'wrote', 'to'),\n",
              " ('wrote', 'to', 'a'),\n",
              " ('to', 'a', 'friend'),\n",
              " ('a', 'friend', 'asking'),\n",
              " ('friend', 'asking', 'her'),\n",
              " ('asking', 'her', 'to'),\n",
              " ('her', 'to', 'look'),\n",
              " ('to', 'look', 'out'),\n",
              " ('look', 'out', 'for'),\n",
              " ('out', 'for', 'a'),\n",
              " ('for', 'a', 'new'),\n",
              " ('a', 'new', 'situation'),\n",
              " ('new', 'situation', 'for'),\n",
              " ('situation', 'for', 'her;'),\n",
              " ('for', 'her;', 'the'),\n",
              " ('her;', 'the', 'man-cook'),\n",
              " ('the', 'man-cook', 'had'),\n",
              " ('man-cook', 'had', 'walked'),\n",
              " ('had', 'walked', 'off'),\n",
              " ('walked', 'off', 'the'),\n",
              " ('off', 'the', 'day'),\n",
              " ('the', 'day', 'before'),\n",
              " ('day', 'before', 'just'),\n",
              " ('before', 'just', 'at'),\n",
              " ('just', 'at', 'dinner'),\n",
              " ('at', 'dinner', 'time;'),\n",
              " ('dinner', 'time;', 'the'),\n",
              " ('time;', 'the', 'kitchen-maid,'),\n",
              " ('the', 'kitchen-maid,', 'and'),\n",
              " ('kitchen-maid,', 'and', 'the'),\n",
              " ('and', 'the', 'coachman'),\n",
              " ('the', 'coachman', 'had'),\n",
              " ('coachman', 'had', 'given'),\n",
              " ('had', 'given', 'warning')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the n grams\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ekZPRsw-lC-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams_count(dataset:list[tuple[str]], n:int) -> dict[str, Counter]:\n",
        "  ngram_counts = defaultdict(Counter)\n",
        "  number_of_tokens = len(dataset)\n",
        "\n",
        "  for token in dataset:\n",
        "    context = \" \".join(token[:-1])\n",
        "    next_token = token[-1]\n",
        "    ngram_counts[context][next_token] +=1\n",
        "\n",
        "  return dict(ngram_counts)\n",
        "\n",
        "\n",
        "\n",
        "tokens = generate_ngrams(dataset, 3)\n",
        "print(generate_ngrams_count(tokens, 3))"
      ],
      "metadata": {
        "id": "UbJoiub6lYRx",
        "outputId": "8d53a56c-54a1-4190-85c9-73683538111d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'happy families': Counter({'are': 1}), 'families are': Counter({'all': 1}), 'are all': Counter({'alike;': 1}), 'all alike;': Counter({'every': 1}), 'alike; every': Counter({'unhappy': 1}), 'every unhappy': Counter({'family': 1}), 'unhappy family': Counter({'is': 1}), 'family is': Counter({'unhappy': 1}), 'is unhappy': Counter({'in': 1}), 'unhappy in': Counter({'its': 1}), 'in its': Counter({'own': 1}), 'its own': Counter({'way.': 1}), 'own way.': Counter({'everything': 1}), 'way. everything': Counter({'was': 1}), 'everything was': Counter({'in': 1}), 'was in': Counter({'confusion': 1}), 'in confusion': Counter({'in': 1}), 'confusion in': Counter({'the': 1}), 'in the': Counter({'oblonskys’': 1, 'same': 1, 'house': 1}), 'the oblonskys’': Counter({'house.': 1}), 'oblonskys’ house.': Counter({'the': 1}), 'house. the': Counter({'wife': 1}), 'the wife': Counter({'had': 1, 'did': 1}), 'wife had': Counter({'discovered': 1}), 'had discovered': Counter({'that': 1}), 'discovered that': Counter({'the': 1}), 'that the': Counter({'husband': 1, 'stray': 1}), 'the husband': Counter({'was': 1, 'and': 1, 'had': 1}), 'husband was': Counter({'carrying': 1}), 'was carrying': Counter({'on': 1}), 'carrying on': Counter({'an': 1}), 'on an': Counter({'intrigue': 1}), 'an intrigue': Counter({'with': 1}), 'intrigue with': Counter({'a': 1}), 'with a': Counter({'french': 1}), 'a french': Counter({'girl,': 1}), 'french girl,': Counter({'who': 1}), 'girl, who': Counter({'had': 1}), 'who had': Counter({'been': 1}), 'had been': Counter({'a': 1}), 'been a': Counter({'governess': 1}), 'a governess': Counter({'in': 1}), 'governess in': Counter({'their': 1}), 'in their': Counter({'family,': 1, 'living': 1}), 'their family,': Counter({'and': 1}), 'family, and': Counter({'she': 1}), 'and she': Counter({'had': 1}), 'she had': Counter({'announced': 1}), 'had announced': Counter({'to': 1}), 'announced to': Counter({'her': 1}), 'to her': Counter({'husband': 1}), 'her husband': Counter({'that': 1}), 'husband that': Counter({'she': 1}), 'that she': Counter({'could': 1}), 'she could': Counter({'not': 1}), 'could not': Counter({'go': 1}), 'not go': Counter({'on': 1}), 'go on': Counter({'living': 1}), 'on living': Counter({'in': 1}), 'living in': Counter({'the': 1}), 'the same': Counter({'house': 1}), 'same house': Counter({'with': 1}), 'house with': Counter({'him.': 1}), 'with him.': Counter({'this': 1}), 'him. this': Counter({'position': 1}), 'this position': Counter({'of': 1}), 'position of': Counter({'affairs': 1}), 'of affairs': Counter({'had': 1}), 'affairs had': Counter({'now': 1}), 'had now': Counter({'lasted': 1}), 'now lasted': Counter({'three': 1}), 'lasted three': Counter({'days,': 1}), 'three days,': Counter({'and': 1}), 'days, and': Counter({'not': 1}), 'and not': Counter({'only': 1}), 'not only': Counter({'the': 1}), 'only the': Counter({'husband': 1}), 'husband and': Counter({'wife': 1}), 'and wife': Counter({'themselves,': 1}), 'wife themselves,': Counter({'but': 1}), 'themselves, but': Counter({'all': 1}), 'but all': Counter({'the': 1}), 'all the': Counter({'members': 1}), 'the members': Counter({'of': 2}), 'members of': Counter({'their': 1, 'the': 1}), 'of their': Counter({'family': 1}), 'their family': Counter({'and': 1}), 'family and': Counter({'household,': 1, 'household': 1}), 'and household,': Counter({'were': 1}), 'household, were': Counter({'painfully': 1}), 'were painfully': Counter({'conscious': 1}), 'painfully conscious': Counter({'of': 1}), 'conscious of': Counter({'it.': 1}), 'of it.': Counter({'every': 1}), 'it. every': Counter({'person': 1}), 'every person': Counter({'in': 1}), 'person in': Counter({'the': 1}), 'the house': Counter({'felt': 1}), 'house felt': Counter({'that': 1}), 'felt that': Counter({'there': 1}), 'that there': Counter({'was': 1}), 'there was': Counter({'no': 1}), 'was no': Counter({'sense': 1}), 'no sense': Counter({'in': 1}), 'sense in': Counter({'their': 1}), 'their living': Counter({'together,': 1}), 'living together,': Counter({'and': 1}), 'together, and': Counter({'that': 1}), 'and that': Counter({'the': 1}), 'the stray': Counter({'people': 1}), 'stray people': Counter({'brought': 1}), 'people brought': Counter({'together': 1}), 'brought together': Counter({'by': 1}), 'together by': Counter({'chance': 1}), 'by chance': Counter({'in': 1}), 'chance in': Counter({'any': 1}), 'in any': Counter({'inn': 1}), 'any inn': Counter({'had': 1}), 'inn had': Counter({'more': 1}), 'had more': Counter({'in': 1}), 'more in': Counter({'common': 1}), 'in common': Counter({'with': 1}), 'common with': Counter({'one': 1}), 'with one': Counter({'another': 1}), 'one another': Counter({'than': 1}), 'another than': Counter({'they,': 1}), 'than they,': Counter({'the': 1}), 'they, the': Counter({'members': 1}), 'of the': Counter({'family': 1, 'oblonskys.': 1}), 'the family': Counter({'and': 1}), 'and household': Counter({'of': 1}), 'household of': Counter({'the': 1}), 'the oblonskys.': Counter({'the': 1}), 'oblonskys. the': Counter({'wife': 1}), 'wife did': Counter({'not': 1}), 'did not': Counter({'leave': 1}), 'not leave': Counter({'her': 1}), 'leave her': Counter({'own': 1}), 'her own': Counter({'room,': 1}), 'own room,': Counter({'the': 1}), 'room, the': Counter({'husband': 1}), 'husband had': Counter({'not': 1}), 'had not': Counter({'been': 1}), 'not been': Counter({'at': 1}), 'been at': Counter({'home': 1}), 'at home': Counter({'for': 1}), 'home for': Counter({'three': 1}), 'for three': Counter({'days.': 1}), 'three days.': Counter({'the': 1}), 'days. the': Counter({'children': 1}), 'the children': Counter({'ran': 1}), 'children ran': Counter({'wild': 1}), 'ran wild': Counter({'all': 1}), 'wild all': Counter({'over': 1}), 'all over': Counter({'the': 1}), 'over the': Counter({'house;': 1}), 'the house;': Counter({'the': 1}), 'house; the': Counter({'english': 1}), 'the english': Counter({'governess': 1}), 'english governess': Counter({'quarreled': 1}), 'governess quarreled': Counter({'with': 1}), 'quarreled with': Counter({'the': 1}), 'with the': Counter({'housekeeper,': 1}), 'the housekeeper,': Counter({'and': 1}), 'housekeeper, and': Counter({'wrote': 1}), 'and wrote': Counter({'to': 1}), 'wrote to': Counter({'a': 1}), 'to a': Counter({'friend': 1}), 'a friend': Counter({'asking': 1}), 'friend asking': Counter({'her': 1}), 'asking her': Counter({'to': 1}), 'her to': Counter({'look': 1}), 'to look': Counter({'out': 1}), 'look out': Counter({'for': 1}), 'out for': Counter({'a': 1}), 'for a': Counter({'new': 1}), 'a new': Counter({'situation': 1}), 'new situation': Counter({'for': 1}), 'situation for': Counter({'her;': 1}), 'for her;': Counter({'the': 1}), 'her; the': Counter({'man-cook': 1}), 'the man-cook': Counter({'had': 1}), 'man-cook had': Counter({'walked': 1}), 'had walked': Counter({'off': 1}), 'walked off': Counter({'the': 1}), 'off the': Counter({'day': 1}), 'the day': Counter({'before': 1}), 'day before': Counter({'just': 1}), 'before just': Counter({'at': 1}), 'just at': Counter({'dinner': 1}), 'at dinner': Counter({'time;': 1}), 'dinner time;': Counter({'the': 1}), 'time; the': Counter({'kitchen-maid,': 1}), 'the kitchen-maid,': Counter({'and': 1}), 'kitchen-maid, and': Counter({'the': 1}), 'and the': Counter({'coachman': 1}), 'the coachman': Counter({'had': 1}), 'coachman had': Counter({'given': 1}), 'had given': Counter({'warning': 1})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute probabilty"
      ],
      "metadata": {
        "id": "NNSM0eJJBhyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngram_model(dataset:str, n:int) -> dict[str, dict[str, float]]:\n",
        "  ngram_model = {}\n",
        "  ngrams = generate_ngrams(dataset, n)\n",
        "  ngrams_count = generate_ngrams_count(ngrams, n)\n",
        "\n",
        "  for context, next_token in ngrams_count.items():\n",
        "    total_count = sum(next_token.values())\n",
        "    ngram_model[context] = {}\n",
        "    for token, count in next_token.items():\n",
        "      ngram_model[context][token] = count / total_count\n",
        "\n",
        "  return ngram_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "new_dataset = \"\"\"\n",
        "Whose woods these are I think I know.\n",
        "His house is in the village though;\n",
        "He will not see me stopping here\n",
        "To watch his woods fill up with snow.\n",
        "\n",
        "My little horse must think it queer\n",
        "To stop without a farmhouse near\n",
        "Between the woods and frozen lake\n",
        "The darkest evening of the year.\n",
        "\n",
        "He gives his harness bells a shake\n",
        "To ask if there is some mistake.\n",
        "The only other sound’s the sweep\n",
        "Of easy wind and downy flake.\n",
        "\n",
        "The woods are lovely, dark and deep,\n",
        "But I have promises to keep,\n",
        "And miles to go before I sleep,\n",
        "And miles to go before I sleep.\n",
        "\"\"\"\n",
        "\n",
        "simple_dataset = \"What is the meaning of life? 42, Maybe. I don't know the meaning of world. Bowing to something\"\n",
        "\n",
        "new_dataset = textwrap.dedent(new_dataset)\n",
        "\n",
        "generate_ngram_model(new_dataset, 2)"
      ],
      "metadata": {
        "id": "Z-HLPb3fBrA4",
        "outputId": "bef55f1a-5123-4c1c-d367-9a27b38b78c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\nwhose': {'woods': 1.0},\n",
              " 'woods': {'these': 0.25, 'fill': 0.25, 'and': 0.25, 'are': 0.25},\n",
              " 'these': {'are': 1.0},\n",
              " 'are': {'i': 0.5, 'lovely,': 0.5},\n",
              " 'i': {'think': 0.2,\n",
              "  'know.\\nhis': 0.2,\n",
              "  'have': 0.2,\n",
              "  'sleep,\\nand': 0.2,\n",
              "  'sleep.\\n': 0.2},\n",
              " 'think': {'i': 0.5, 'it': 0.5},\n",
              " 'know.\\nhis': {'house': 1.0},\n",
              " 'house': {'is': 1.0},\n",
              " 'is': {'in': 0.5, 'some': 0.5},\n",
              " 'in': {'the': 1.0},\n",
              " 'the': {'village': 0.25,\n",
              "  'woods': 0.25,\n",
              "  'year.\\n\\nhe': 0.25,\n",
              "  'sweep\\nof': 0.25},\n",
              " 'village': {'though;\\nhe': 1.0},\n",
              " 'though;\\nhe': {'will': 1.0},\n",
              " 'will': {'not': 1.0},\n",
              " 'not': {'see': 1.0},\n",
              " 'see': {'me': 1.0},\n",
              " 'me': {'stopping': 1.0},\n",
              " 'stopping': {'here\\nto': 1.0},\n",
              " 'here\\nto': {'watch': 1.0},\n",
              " 'watch': {'his': 1.0},\n",
              " 'his': {'woods': 0.5, 'harness': 0.5},\n",
              " 'fill': {'up': 1.0},\n",
              " 'up': {'with': 1.0},\n",
              " 'with': {'snow.\\n\\nmy': 1.0},\n",
              " 'snow.\\n\\nmy': {'little': 1.0},\n",
              " 'little': {'horse': 1.0},\n",
              " 'horse': {'must': 1.0},\n",
              " 'must': {'think': 1.0},\n",
              " 'it': {'queer\\nto': 1.0},\n",
              " 'queer\\nto': {'stop': 1.0},\n",
              " 'stop': {'without': 1.0},\n",
              " 'without': {'a': 1.0},\n",
              " 'a': {'farmhouse': 0.5, 'shake\\nto': 0.5},\n",
              " 'farmhouse': {'near\\nbetween': 1.0},\n",
              " 'near\\nbetween': {'the': 1.0},\n",
              " 'and': {'frozen': 0.3333333333333333,\n",
              "  'downy': 0.3333333333333333,\n",
              "  'deep,\\nbut': 0.3333333333333333},\n",
              " 'frozen': {'lake\\nthe': 1.0},\n",
              " 'lake\\nthe': {'darkest': 1.0},\n",
              " 'darkest': {'evening': 1.0},\n",
              " 'evening': {'of': 1.0},\n",
              " 'of': {'the': 1.0},\n",
              " 'year.\\n\\nhe': {'gives': 1.0},\n",
              " 'gives': {'his': 1.0},\n",
              " 'harness': {'bells': 1.0},\n",
              " 'bells': {'a': 1.0},\n",
              " 'shake\\nto': {'ask': 1.0},\n",
              " 'ask': {'if': 1.0},\n",
              " 'if': {'there': 1.0},\n",
              " 'there': {'is': 1.0},\n",
              " 'some': {'mistake.\\nthe': 1.0},\n",
              " 'mistake.\\nthe': {'only': 1.0},\n",
              " 'only': {'other': 1.0},\n",
              " 'other': {'sound’s': 1.0},\n",
              " 'sound’s': {'the': 1.0},\n",
              " 'sweep\\nof': {'easy': 1.0},\n",
              " 'easy': {'wind': 1.0},\n",
              " 'wind': {'and': 1.0},\n",
              " 'downy': {'flake.\\n\\nthe': 1.0},\n",
              " 'flake.\\n\\nthe': {'woods': 1.0},\n",
              " 'lovely,': {'dark': 1.0},\n",
              " 'dark': {'and': 1.0},\n",
              " 'deep,\\nbut': {'i': 1.0},\n",
              " 'have': {'promises': 1.0},\n",
              " 'promises': {'to': 1.0},\n",
              " 'to': {'keep,\\nand': 0.3333333333333333, 'go': 0.6666666666666666},\n",
              " 'keep,\\nand': {'miles': 1.0},\n",
              " 'miles': {'to': 1.0},\n",
              " 'go': {'before': 1.0},\n",
              " 'before': {'i': 1.0},\n",
              " 'sleep,\\nand': {'miles': 1.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate tokens based on the model"
      ],
      "metadata": {
        "id": "v31hsmUIL9dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_next_tokens(\n",
        "    n:int, ngram_model:dict[str, dict[str, float]],\n",
        "    prompt:str,\n",
        "    tokens_to_generate:int) -> str:\n",
        "\n",
        "    generated_words = prompt.split(\" \")\n",
        "\n",
        "    for _ in range(tokens_to_generate):\n",
        "      context = generated_words[-(n - 1):]\n",
        "      context = \" \".join(context)\n",
        "      if context in ngram_model:\n",
        "        next_word = random.choices(list(ngram_model[context].keys()),\n",
        "                                   weights=ngram_model[context].values())[0]\n",
        "        generated_words.append(next_word)\n",
        "      else:\n",
        "        print(\"context not present\")\n",
        "\n",
        "    return \" \".join(generated_words)\n",
        "\n",
        "\n",
        "\n",
        "n = 2\n",
        "bigram_model = generate_ngram_model(new_dataset, 2)\n",
        "prompt = \"Whoose houses are these\"\n",
        "tokens_to_generate = 5\n",
        "generate_next_tokens(n, bigram_model, prompt, tokens_to_generate)"
      ],
      "metadata": {
        "id": "qEnZQLTqMDtd",
        "outputId": "16864064-7bfb-4929-efa8-0d5060fa41f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Whoose houses are these are lovely, dark and frozen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}